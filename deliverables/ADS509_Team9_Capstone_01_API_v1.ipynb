{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e49e21-4b1f-4603-a619-84b9e1998f03",
   "metadata": {},
   "source": [
    "# 599 Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32969aa-7653-4aab-a91f-52dc53dc26e5",
   "metadata": {},
   "source": [
    "This notebook connects to the NewAPI to return JSOn objects based on specific queries, loads specific elements from the object, then persists the data in an existing MySQL table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41799b8c-019d-4d02-914a-107c15e3c572",
   "metadata": {},
   "source": [
    "## Resolve dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156706dd-43a9-49ff-8fa3-f61f0dc9cb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newsapi-python in c:\\users\\acarr\\anaconda3\\envs\\ds-py38-cs\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\acarr\\anaconda3\\envs\\ds-py38-cs\\lib\\site-packages (from newsapi-python) (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\acarr\\anaconda3\\envs\\ds-py38-cs\\lib\\site-packages (from requests<3.0.0->newsapi-python) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\acarr\\anaconda3\\envs\\ds-py38-cs\\lib\\site-packages (from requests<3.0.0->newsapi-python) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\acarr\\anaconda3\\envs\\ds-py38-cs\\lib\\site-packages (from requests<3.0.0->newsapi-python) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acarr\\anaconda3\\envs\\ds-py38-cs\\lib\\site-packages (from requests<3.0.0->newsapi-python) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "! pip install newsapi-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c57862-dbc2-4515-b62e-14adccbf6d2b",
   "metadata": {},
   "source": [
    "## Globally import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9652c564-af01-4aad-ac50-2afcd910c4e6",
   "metadata": {},
   "source": [
    "Libraries needed mostly pertain to file access, dataframe manipulation, and NewsAPI call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c1e3ef-8619-4237-88c3-e4a06edaf6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymysql as mysql\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import logging\n",
    "import time\n",
    "import zipfile\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "import re\n",
    "import regex as rex\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "\n",
    "from newsapi import NewsApiClient\n",
    "\n",
    "# Set pandas global options\n",
    "pd.options.display.max_rows = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8787f58-5e3f-4200-b947-3fc11d9b00e1",
   "metadata": {},
   "source": [
    "## Connect to NewsAPI client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e194aa0a-a644-4b0e-a73f-68e667530b72",
   "metadata": {},
   "source": [
    "Pull masked key from environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fae3237-1881-4b51-8ef3-89d519df07e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ['NewsAPIKey']\n",
    "\n",
    "# Init APO connection\n",
    "newsapi = NewsApiClient(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ace829b-46ef-4364-98ca-e8bddf331a8a",
   "metadata": {},
   "source": [
    "### Pull article info from API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352d698-8a6d-48a3-8385-ba2bee3996ca",
   "metadata": {},
   "source": [
    "Get source info in order to setup API call correctly. *Note:* Display turned off due to size of output."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c833d54d-22e7-45a4-9f10-be07a1e4b596",
   "metadata": {},
   "source": [
    "sources = newsapi.get_sources(language='en',\n",
    "                              country='us')\n",
    "display(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283e6f89-f0dd-4e93-9e13-0b54ba325bca",
   "metadata": {},
   "source": [
    "### Define custom function for API call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b0ce5-995a-48ec-9b09-06ae56f8748f",
   "metadata": {},
   "source": [
    "Use the newsapi package `.get_everything()` call structure to retrieve articles based on a combination of key word query, source/domain, from/to dates, language (English-only), and number of pages returned (NewsAPI returns a max. of 100 articles per page). The results are appended to an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee1b41dd-e69a-40b7-baaa-ab45308d24e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_api_urls(q=None,\n",
    "                  s=None,\n",
    "                  d_from='2023-05-01',\n",
    "                  d_to='2023-05-31',\n",
    "                  page=1,\n",
    "                  api_lst=[]):\n",
    "    '''Access API and pull content from resulting JSON object'''\n",
    "    all_articles = newsapi.get_everything(q=q,\n",
    "                                          domains=s,\n",
    "                                          from_param=d_from,\n",
    "                                          to=d_to,\n",
    "                                          language='en',\n",
    "                                          sort_by='popularity',\n",
    "                                          page=page)\n",
    "\n",
    "    #print(type(all_articles))\n",
    "    #print(all_articles)\n",
    "    #print('Article list: ', all_articles['articles'])\n",
    "    #for article in all_articles['articles']:\n",
    "        #print('Source ID:', article['source']['id'])\n",
    "        #print('Source name:', article['source']['name'])\n",
    "        #print('Author:', article['author'])\n",
    "        #print('Title:', article['title'])\n",
    "        #print('URL:', article['url'])\n",
    "        #print('Publish date:', article['publishedAt'])\n",
    "        #print('Article text:', article['content'], '\\n')\n",
    "\n",
    "    # Create a list of tuples from the dictionary data\n",
    "    source_data01 = [(a['source']['name'],\n",
    "                      a['author'],\n",
    "                      a['title'],\n",
    "                      a['url'],\n",
    "                      a['publishedAt'],\n",
    "                      a['content'])\n",
    "                     for a in all_articles['articles']]\n",
    "\n",
    "    api_lst.extend(source_data01)\n",
    "    #print(api_lst)\n",
    "    return(len(api_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e798fa2-c6c3-403a-9447-45ce85b22b02",
   "metadata": {},
   "source": [
    "### Establish connection to API to access URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb7d5cf-9cdf-48a6-859d-3ea5fd230015",
   "metadata": {},
   "source": [
    "#### Set API filter parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a065004-db65-4d58-b5d1-51a2fd65bec9",
   "metadata": {},
   "source": [
    "The specific list of sources/domains was established to cast a wider net in order to maximize the diversity of content, while attempting to capture a combination of the most popular and/or mainstream online news source content (articles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15a1330d-6e03-4e1f-b2c6-6393d2a89ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total API request grid: Sources x dates\n",
    "#source_str = 'cnn, fox-news, the-wall-street-journal, abc-news, the-huffington-post, buzzfeed, breitbart-news, the-washington-post, usa-today, business-insider, nbc-news, msnbc, reuters, wired'\n",
    "source_str = 'nypost.com, nytimes.com, msn.com, people.com, cnbc.com, forbes.com, vox.com'\n",
    "#date_lst = ['2023-06-30', '2023-06-29', '2023-06-28', '2023-06-27', '2023-06-26',\n",
    "#            '2023-06-25', '2023-06-24', '2023-06-23', '2023-06-22', '2023-06-21',\n",
    "#            '2023-06-24', '2023-06-23', '2023-06-22', '2023-06-21', '2023-06-20',]\n",
    "\n",
    "#date_lst = ['2023-06-19', '2023-06-18', '2023-06-17', '2023-06-16', '2023-06-15',\n",
    "#            '2023-06-14', '2023-06-13', '2023-06-12', '2023-06-11', '2023-06-10',]\n",
    "\n",
    "#date_lst = ['2023-06-09', '2023-06-08', '2023-06-07', '2023-06-06', '2023-06-05',\n",
    "#            '2023-06-04', '2023-06-03', '2023-06-02', '2023-06-01', '2023-05-31',]\n",
    "\n",
    "#date_lst = ['2023-05-30', '2023-05-29', '2023-05-28', '2023-05-27', '2023-05-26',\n",
    "#            '2023-05-25', '2023-05-24', '2023-05-23', '2023-05-22', '2023-05-21',]\n",
    "\n",
    "#date_lst = ['2023-05-20', '2023-05-19', '2023-05-18', '2023-05-17', '2023-05-16',\n",
    "#            '2023-05-15', '2023-05-14', '2023-05-13', '2023-05-12', '2023-05-11',]\n",
    "\n",
    "date_lst = ['2023-05-10', '2023-05-09', '2023-05-08', '2023-05-07', '2023-05-06',\n",
    "            '2023-05-05', '2023-05-04', '2023-05-03', '2023-05-02', '2023-05-01',]\n",
    "\n",
    "q_word_lst = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe7168-8e57-457b-b8e9-2effd17f2e4b",
   "metadata": {},
   "source": [
    "### Access API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf0ea25-8c9c-40f1-b128-8a08045c72f0",
   "metadata": {},
   "source": [
    "Run the custom function through a `for` loop to prevent over-loading calls to the API. For each date in `date_lst`, and for each page in the range of 1 to 10, the `news_api_urls` function will access the entered source/domains (as a string), appending the results to `api_lst`. A random sleep step was added to prevent rate limiting by the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5960daa3-3823-40f5-8869-1334e040e838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story Count: 100; Story Count: 200; Story Count: 288; Story Count: 288; Story Count: 288; Story Count: 288; Story Count: 288; Story Count: 288; Story Count: 288; Story Count: 288; Story Count: 388; Story Count: 488; Story Count: 588; Story Count: 688; Story Count: 788; Story Count: 830; Story Count: 830; Story Count: 830; Story Count: 830; Story Count: 830; Story Count: 930; Story Count: 1030; Story Count: 1130; Story Count: 1230; Story Count: 1330; Story Count: 1430; Story Count: 1477; Story Count: 1477; Story Count: 1477; Story Count: 1477; Story Count: 1577; Story Count: 1677; Story Count: 1777; Story Count: 1877; Story Count: 1977; Story Count: 2077; Story Count: 2157; Story Count: 2157; Story Count: 2157; Story Count: 2157; Story Count: 2257; Story Count: 2357; Story Count: 2457; Story Count: 2557; Story Count: 2657; Story Count: 2757; Story Count: 2835; Story Count: 2835; Story Count: 2835; Story Count: 2835; Story Count: 2935; Story Count: 3035; Story Count: 3135; Story Count: 3235; Story Count: 3335; Story Count: 3402; Story Count: 3402; Story Count: 3402; Story Count: 3402; Story Count: 3402; Story Count: 3502; Story Count: 3602; Story Count: 3624; Story Count: 3624; Story Count: 3624; Story Count: 3624; Story Count: 3624; Story Count: 3624; Story Count: 3624; Story Count: 3624; Story Count: 3724; Story Count: 3824; Story Count: 3900; Story Count: 3900; Story Count: 3900; Story Count: 3900; Story Count: 3900; Story Count: 3900; Story Count: 3900; Story Count: 3900; Story Count: 4000; Story Count: 4100; Story Count: 4200; Story Count: 4300; Story Count: 4400; Story Count: 4500; Story Count: 4504; Story Count: 4504; Story Count: 4504; Story Count: 4504; Story Count: 4604; Story Count: 4704; Story Count: 4804; Story Count: 4904; Story Count: 5004; Story Count: 5104; Story Count: 5178; Story Count: 5178; Story Count: 5178; Story Count: 5178; "
     ]
    }
   ],
   "source": [
    "'''Run individual request for each source/data/keyword combo\n",
    "to maximize data scraped'''\n",
    "api_record_lst01 = []\n",
    "\n",
    "for d in date_lst:\n",
    "    for p in range(1, 11):\n",
    "        time.sleep(5 + 11 * random.random())\n",
    "        try:\n",
    "            lst_len = news_api_urls(s=source_str,\n",
    "                                    d_from=d,\n",
    "                                    d_to=d,\n",
    "                                    page=p,\n",
    "                                    api_lst=api_record_lst01)\n",
    "        except:\n",
    "            print(f'Page {p} is not available for {d}')\n",
    "        print(f'Story Count: {lst_len}; ', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57413734-5056-4571-9708-6916e15caed8",
   "metadata": {},
   "source": [
    "Print size number of API records returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84a04f8c-c5d3-4236-998a-a13bf09c0c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5178\n"
     ]
    }
   ],
   "source": [
    "print(len(api_record_lst01))\n",
    "#print(api_record_lst01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b80bb74-6bb0-4f68-a4e5-418bf5a82332",
   "metadata": {},
   "source": [
    "Convert the list to set in case there are duplicate URLs, the convert the set back to list type for use in MySQL transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f82433d-b1a9-4c22-b3b1-ac3c8208e8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5043\n"
     ]
    }
   ],
   "source": [
    "# Convert result list to set to eliminate duplicates\n",
    "api_record_set01 = set(api_record_lst01)\n",
    "#print(api_record_set01)\n",
    "api_record_lst02 = list(api_record_set01)\n",
    "#print(api_record_lst02)\n",
    "print(len(api_record_lst02))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff0feec-4930-4d28-a6c2-d83288b781b7",
   "metadata": {},
   "source": [
    "## Initiate MySQL connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb904a1-309b-43ff-b410-be70eca9cb15",
   "metadata": {},
   "source": [
    "Open connection to existing MySQL schema and table. Pull masked user and password from environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d1e9561-e376-4262-aa6f-c59d45124989",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Set local environment variables to hide user name & password citation:\n",
    "https://www.geeksforgeeks.org/how-to-hide-sensitive-credentials-using-python/\n",
    "'''\n",
    "user_name = os.environ['MySQLUSRAC']\n",
    "user_pass = os.environ['MySQLPWDAC']\n",
    "\n",
    "# Instantiate connection\n",
    "db_conn = mysql.connect(host='localhost',\n",
    "                        port=int(3306),\n",
    "                        user=user_name,\n",
    "                        passwd=user_pass,\n",
    "                        db='599_capstone')\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = db_conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c8675c-3b65-4eb6-90ee-6aa3cf4dc108",
   "metadata": {},
   "source": [
    "Display schema tables to ensure the connection was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e753d762-a5ea-455a-8db6-b329eed96d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tables_in_599_capstone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nar_temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news_articles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Tables_in_599_capstone\n",
       "0               nar_temp\n",
       "1          news_articles"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "tbl_names = pd.read_sql('SHOW TABLES', db_conn)\n",
    "\n",
    "display(tbl_names)\n",
    "print(type(tbl_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afd8db1-f81b-4b75-adbf-546c19cfab8b",
   "metadata": {},
   "source": [
    "### Establish logging policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3921ce43-5159-44b5-befa-beaead56f78f",
   "metadata": {},
   "source": [
    "Configure logging so that connection errors can be reviewed. Logging output is sent to the pymysql.log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45f9b045-77c7-46b9-98ed-cb15b224bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Logging citations:\n",
    "1. https://chat.openai.com/share/7d376dad-eb91-40b7-b84f-55286fb29d35\n",
    "2. https://docs.python.org/3/howto/logging.html#logging-basic-example\n",
    "3. https://docs.python.org/3/howto/logging.html#logging-to-a-file\n",
    "4. https://docs.python.org/3/howto/logging-cookbook.html#using-a-rotating-log-file-handler\n",
    "5. https://docs.python.org/3/howto/logging-cookbook.html#using-a-timed-rotating-file-handler\n",
    "'''\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    filename='pymysql.log',\n",
    "                    filemode='a',\n",
    "                    format='''>>>>>>>>>>>>>><<<<<<<<<<<<<<\\n%(asctime)s - %(levelname)s - %(message)s''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5204295-2b32-45bf-b851-45f40fc5fdcf",
   "metadata": {},
   "source": [
    "### Update individual tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e51a9b-96b9-4e0d-ba5f-ef6acc5b60ef",
   "metadata": {},
   "source": [
    "#### Update `news_articles` table from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dead612-d53c-4ea6-b574-1248c09b21aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nat_tbl_name = 'nar_temp'\n",
    "nwa_tbl_name = 'news_articles'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a26e14-d71b-4b48-8963-8738daba31d7",
   "metadata": {},
   "source": [
    "Load the list of API record results to a temporary MySQL table. Then update the main MySQL table by adding records based on a join with the temporary table. Using `title`, `publish_date`, and `author` as the join criteria ensures that only new URLs are added. The code block starts and ends with a wipe of the temp table. Also, the logging criteria has been embedded in order to output any errors generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6f4422f-123d-4d05-bcc8-7e41cfe08d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Using cursor and loading into temp file:\n",
    "OpenAI. (2021). ChatGPT [Computer software]. https://openai.com/;\n",
    "https://pynative.com/python-mysql-insert-data-into-database-table/\n",
    "'''\n",
    "\n",
    "# Execute query and measure execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Wipe temp table\n",
    "try:\n",
    "    nat_dlt_tble_stmnt = f\"\"\"DELETE FROM {nat_tbl_name}\"\"\"\n",
    "    cursor.execute(nat_dlt_tble_stmnt)\n",
    "    logging.info(f'''Successfully executed query:\\n{nat_dlt_tble_stmnt}\\n\\nRecords scanned: {cursor.rowcount}''')\n",
    "except mysql.Error as e:\n",
    "    logging.error(f'Error executing query:\\n{nat_dlt_tble_stmnt}\\n\\n{e}')\n",
    "finally:\n",
    "    end_time = time.time()\n",
    "    logging.info(f'''Time taken: {end_time - start_time:.3f} seconds\\n>>>>>>>>>>>>>><<<<<<<<<<<<<<\\n\\n''')\n",
    "\n",
    "# Execute query and measure execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load data from CSV file into a temporary table\n",
    "try:\n",
    "    nat_csv_load_stmnt = f\"\"\"\n",
    "    INSERT INTO {nat_tbl_name}\n",
    "    (\n",
    "    source_name,\n",
    "    author,\n",
    "    title,\n",
    "    url,\n",
    "    publish_date,\n",
    "    content\n",
    "    )\n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query with multiple values\n",
    "    cursor.executemany(nat_csv_load_stmnt, api_record_lst02)\n",
    "    #cursor.execute(nat_csv_load_stmnt)\n",
    "    logging.info(f'''Successfully executed query:\\n{nat_csv_load_stmnt}\\n\\nRecords scanned: {cursor.rowcount}''')\n",
    "except mysql.Error as e:\n",
    "    logging.error(f'Error executing query:\\n{nat_csv_load_stmnt}\\n\\n{e}')\n",
    "finally:\n",
    "    end_time = time.time()\n",
    "    logging.info(f'''Time taken: {end_time - start_time:.3f} seconds\\n>>>>>>>>>>>>>><<<<<<<<<<<<<<\\n\\n''')\n",
    "\n",
    "# Execute query and measure execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Insert new records into main table\n",
    "try:\n",
    "    nwa_load_stmnt = f\"\"\"\n",
    "    INSERT INTO {nwa_tbl_name}\n",
    "    (\n",
    "    source_name,\n",
    "    author,\n",
    "    title,\n",
    "    url,\n",
    "    publish_date,\n",
    "    content\n",
    "    )\n",
    "    SELECT\n",
    "        tp.source_name,\n",
    "        tp.author,\n",
    "        tp.title,\n",
    "        tp.url,\n",
    "        tp.publish_date,\n",
    "        tp.content\n",
    "    FROM {nat_tbl_name} AS tp\n",
    "    LEFT JOIN {nwa_tbl_name} AS mn\n",
    "    ON tp.title = mn.title\n",
    "        AND CAST(LEFT(tp.publish_date,10) AS DATE)=CAST(LEFT(mn.publish_date,10) AS DATE)\n",
    "        AND tp.author = mn.author\n",
    "    \"\"\"\n",
    "    cursor.execute(nwa_load_stmnt)\n",
    "    logging.info(f'''Successfully executed query:\\n{nwa_load_stmnt}\\n\\nRecords scanned: {cursor.rowcount}''')\n",
    "except mysql.Error as e:\n",
    "    logging.error(f'Error executing query:\\n{nwa_load_stmnt}\\n\\n{e}')\n",
    "finally:\n",
    "    end_time = time.time()\n",
    "    logging.info(f'''Time taken: {end_time - start_time:.3f} seconds\\n>>>>>>>>>>>>>><<<<<<<<<<<<<<\\n\\n''')\n",
    "\n",
    "# Execute query and measure execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Wipe temp table\n",
    "try:\n",
    "    cursor.execute(nat_dlt_tble_stmnt)\n",
    "    logging.info(f'''Successfully executed query:\\n{nat_dlt_tble_stmnt}\\n\\nRecords scanned: {cursor.rowcount}''')\n",
    "except mysql.Error as e:\n",
    "    logging.error(f'Error executing query:\\n{nat_dlt_tble_stmnt}\\n\\n{e}')\n",
    "finally:\n",
    "    end_time = time.time()\n",
    "    logging.info(f'''Time taken: {end_time - start_time:.3f} seconds\\n>>>>>>>>>>>>>><<<<<<<<<<<<<<\\n\\n''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5699729c-2960-4519-b287-9a6f315a7e35",
   "metadata": {},
   "source": [
    "### Commit changes and close cursor and connection instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ad63f-b6c0-447f-b1ac-eb506f3a3d86",
   "metadata": {},
   "source": [
    "This step is integral to committing any remaining MySQL calls, as well as releasing the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce9228f3-083f-4fc1-850d-fc5e4bde40b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the changes to the database\n",
    "db_conn.commit()\n",
    "\n",
    "# Close the cursor and database connection\n",
    "cursor.close()\n",
    "db_conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
