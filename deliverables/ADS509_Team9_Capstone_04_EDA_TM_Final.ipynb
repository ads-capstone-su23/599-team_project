{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5391b3ea-96a4-48f9-bcf2-57bd926c3529",
   "metadata": {
    "id": "fa1fb104",
    "tags": []
   },
   "source": [
    "# Daily Retreat: Using Sentiment Analysis to<br>Find, Personalize, and Share Positive News from Popular Online Sources\n",
    "__Aaron Carr, Azucena Faus, and Dave Friesen - ADS-599-01-SU23__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e49e21-4b1f-4603-a619-84b9e1998f03",
   "metadata": {},
   "source": [
    "# Final EDA\n",
    "\n",
    "* Import Libraries\n",
    "\n",
    "* Define Functions for EDA\n",
    "\n",
    "* Load Cleaned/tokenized data\n",
    "\n",
    "* EDA  \n",
    "    * Format publish_date for time-based visualizations\n",
    "    * Find nulls/missing data\n",
    "    * Descriptive Statistics\n",
    "    * Word Cloud for entire corpus\n",
    "    * Topic Modeling using Non-Negative Matrix Factorization\n",
    "    * Topic Modeling using Latent Dirichlet Allocation\n",
    "    * Coherence scores for both methods\n",
    "    * Coherence vs number of Topics LDA\n",
    "    * Coherence vs number of Topics NMF\n",
    "    * NMF Word Cloud\n",
    "    * LDA Word Cloud\n",
    "    * Topical Distribution per Day Trends charts\n",
    "    * Topical Distribution of entire Corpus\n",
    "    * Closer look at the Amazon Reviews topic in the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c57862-dbc2-4515-b62e-14adccbf6d2b",
   "metadata": {},
   "source": [
    "## Globally import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c1e3ef-8619-4237-88c3-e4a06edaf6c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textstat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtextstat\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextstat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m textstat\n\u001b[0;32m     34\u001b[0m legacy_round \u001b[38;5;241m=\u001b[39m textstat\u001b[38;5;241m.\u001b[39m_legacy_round\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textstat'"
     ]
    }
   ],
   "source": [
    "#! pip install pyLDavis\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Text preprocessing libraries\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import logging\n",
    "import time\n",
    "import zipfile\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import re\n",
    "import regex as rex\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import json\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import emoji\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "# EDA for text libraries\n",
    "import nltk\n",
    "import collections\n",
    "import textstat\n",
    "from textstat import textstat\n",
    "legacy_round = textstat._legacy_round\n",
    "lang = 'en'\n",
    "textstat.set_lang(lang)\n",
    "from collections import defaultdict, Counter\n",
    "from gensim.corpora import Dictionary\n",
    "import random\n",
    "#import textacy.preprocessing as tprep\n",
    "#from textacy.extract import keyword_in_context\n",
    "import pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "from tqdm.auto import tqdm\n",
    "#import spacy\n",
    "import pyLDAvis.lda_model\n",
    "import pyLDAvis.gensim_models\n",
    "from wordcloud import WordCloud \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from gensim import models, interfaces, utils\n",
    "from gensim.models import Nmf\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "# visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import calendar \n",
    "from tabulate import tabulate\n",
    "\n",
    "# modeling\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import statsmodels.tools.tools as stattools\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tabulate import tabulate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn  import metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf7e4b",
   "metadata": {},
   "source": [
    "## Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6f0d76",
   "metadata": {},
   "source": [
    "### Data pre-processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6e6389",
   "metadata": {},
   "source": [
    "REGEX and NORMALIZE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcff03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rex_sep = rex.compile(r'&nbsp;')\n",
    "rex_ucode = rex.compile(r'[\\\\]u20*')\n",
    "\n",
    "'''re.sub lambda citation:\n",
    "https://chat.openai.com/share/402ec66e-2802-4cda-af8c-6f9f5b097d85\n",
    "'''\n",
    "sep_lst = []\n",
    "ucode_lst = []\n",
    "# Add leading and trailing space to URLs\n",
    "def rex_replace(text):\n",
    "    #txt = str(text)\n",
    "    #print(lambda x: x.replace('&nbsp;', ' '))\n",
    "    #sep_lst.append(rex_sep.findall(txt))\n",
    "    #ucode_lst.append(rex_ucode.findall(txt))\n",
    "    text = text.replace(r'&nbsp;', ' ').replace(r'-', ' ')\\\n",
    "    .replace(r'\\n', ' ').replace('\\u2063', ' ').replace('\\u2066', ' ')\\\n",
    "    .replace('\\u2069', ' ').replace('\\u200b', ' ').replace('\\u200d', ' ')\\\n",
    "    .replace('(click to view)', ' ')\\\n",
    "    .replace('a post shared by', ' ')\\\n",
    "    .replace('app users click here', ' ')\\\n",
    "    .replace('app users: click here', ' ')\\\n",
    "    .replace('app users, click here:', ' ')\\\n",
    "    .replace('click here.', ' ')\\\n",
    "    .replace('click here for more cartoons', ' ')\\\n",
    "    .replace('click here for more', ' ')\\\n",
    "    .replace('click here for more sports coverage on foxnews.com', ' ')\\\n",
    "    .replace('click here for other fox news digital adoptable pets stories', ' ')\\\n",
    "    .replace('click here for the fox news app', ' ')\\\n",
    "    .replace('click here for the latest fox news reporting', ' ')\\\n",
    "    .replace('click here for topline and cross tabs conducted', ' ')\\\n",
    "    .replace('click here to hear more', ' ')\\\n",
    "    .replace('click here to ge the fox news app', ' ')\\\n",
    "    .replace('click here to get the fox news app', ' ')\\\n",
    "    .replace('click here to get the opinion newsletter', ' ')\\\n",
    "    .replace('click here to learn more', ' ')\\\n",
    "    .replace('click here to read more', ' ')\\\n",
    "    .replace('click here to sign up for our health newsletter', ' ')\\\n",
    "    .replace('click here to sign up for our lifestyle newsletter', ' ')\\\n",
    "    .replace('click here to sign up for our opinion newsletter', ' ')\\\n",
    "    .replace('click here to sign up for the entertainment newsletter', ' ')\\\n",
    "    .replace('click here to subscribe and get your first year of fox nation free of charge', ' ')\\\n",
    "    .replace('click here to view', ' ')\\\n",
    "    .replace(\"click to get kurt's cyberguy newsletter with quick tips, tech reviews, security alerts and easy how to's to make you smarter\", ' ')\\\n",
    "    .replace(\"click to get kurt's cyberguy newsletter with security alerts, quick tips, tech reviews, security and easy how to's to make you smarter\", ' ')\\\n",
    "    .replace(\"click to get kurt's free cyberguy newsletter with quick tips, tech reviews, security alerts and easy how to's to make you smarter\", ' ')\\\n",
    "    .replace(\"click to get kurt's free cyberguy newsletter with security alerts, quick tips, tech reviews, and easy how to's to make you smarter\", ' ')\\\n",
    "    .replace('click to get the fox news app', ' ')\\\n",
    "    .replace('fox news digital', ' ')\\\n",
    "    .replace('request for comment', ' ')\\\n",
    "    .replace('the ap ', ' ')\\\n",
    "    .replace('copyright © 2023 breitbart', ' ')\\\n",
    "    .replace('all rights reserved', ' ')\\\n",
    "    .replace('copyright 2023 cyberguy.com', ' ')\\\n",
    "    .replace('copyright 2023 fox news network', ' ')\\\n",
    "    .replace('copyright 2023 viq media transcription', ' ')\\\n",
    "    .replace(\"please let us know if you're having issues with commenting\", ' ')\\\n",
    "    .replace('view this post on instagram', ' ')\n",
    "    #txt = txt\n",
    "    #text = text.replace(r'200b', 'd171c')\n",
    "    #text = rex_ucode.sub('', text)\n",
    "    return text\n",
    "\n",
    "def normalize(text):\n",
    "    text = tprep.normalize.hyphenated_words(text)\n",
    "    text = tprep.normalize.quotation_marks(text)\n",
    "    text = tprep.normalize.unicode(text)\n",
    "    text = tprep.remove.accents(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6fb9ae",
   "metadata": {},
   "source": [
    "LEMMATIZATION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245cc3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp_trans = spacy.load('en_core_web_sm')\n",
    "\n",
    "#def lemma(text):\n",
    "#    trans_txt = nlp_trans(text)\n",
    "#    tokens = [t.lemma_ for t in trans_txt]\n",
    "#    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801cf64d",
   "metadata": {},
   "source": [
    "* CASE LOAD \n",
    "* STOPWORD REMOVAL \n",
    "* URL REMOVAL \n",
    "* EMOJI REMOVAL \n",
    "* PUNCTUATION REMOVAL \n",
    "* MESSY TEXT REMOVAL\n",
    "* TOKENIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE LOAD, REMOVE STOPWORDS,\n",
    "# EMOJI and PUNCTUATION REMAL,\n",
    "# URL REMOVAL\n",
    "# TOKENIZE\n",
    "# REMOVE MESSY text\n",
    "\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "tw_punct = punctuation - {\"#\"}\n",
    "\n",
    "sw = stopwords.words(\"english\")\n",
    "sw = sw + ['nan']\n",
    "sw = sw + ['said'] + ['news'] + ['us'] + ['reuters'] + ['ap'] \\\n",
    "    + ['fox'] + ['cnn'] + ['breitbart'] + ['digital'] + ['follow'] \\\n",
    "    + ['associated press'] + ['press contributed'] + ['press'] \\\n",
    "    + ['dont'] + ['2023'] + ['told digital'] + ['associated contributed']\\\n",
    "    + ['contributed report'] + ['associated'] + ['contributed'] +\\\n",
    "    ['report'] + ['continued'] + ['reportedly'] + ['im']\n",
    "\n",
    "# Two useful regex\n",
    "whitespace_pattern = re.compile(r\"\\s+\")\n",
    "hashtag_pattern = re.compile(r\"^#[0-9a-zA-Z]+\")\n",
    "\n",
    "def emoji_split(text):\n",
    "    return(\"\".join([' ' + ch + ' ' if emoji.is_emoji(ch) else ch for ch in text]))\n",
    "\n",
    "def remove_stop(tokens) :\n",
    "    # modify this function to remove stopwords\n",
    "\n",
    "    return[t for t in tokens if t not in sw]\n",
    " \n",
    "def remove_punctuation(text, punct_set=tw_punct) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "def tokenize(text) : \n",
    "    \"\"\" Splitting on whitespace rather than the book's tokenize function. That \n",
    "        function will drop tokens like '#hashtag' or '2A', which we need for Twitter. \"\"\"\n",
    "    \n",
    "    return([item.lower() for item in whitespace_pattern.split(text)])\n",
    "    \n",
    "def remove_url(text):\n",
    "    return(re.sub(r'http\\S+', '', text))\n",
    "\n",
    "def remove_messy(text): # remove words that give away the source\n",
    "    text1=re.sub(r'cnn', '', text)\n",
    "    text2=re.sub(r'fox', '', text1)\n",
    "    text3=re.sub(r' — ', '', text2)\n",
    "    text4=re.sub(r'breitbart', '', text3)\n",
    "    return(re.sub(r'\\\\n', '', text4))\n",
    "\n",
    "# two pipelines to either tokenize or simply remove punctuation\n",
    "# and lowercase as we will need to extract feature words:\n",
    "\n",
    "full_pipeline = [str.lower, remove_url, rex_replace, emoji_split, remove_messy, \n",
    "                 remove_punctuation, tokenize, remove_stop]\n",
    "first_pipeline = [str.lower, remove_url, rex_replace, emoji_split, remove_messy, \n",
    "                  remove_punctuation]\n",
    "tokenize_sw_pipeline = [remove_punctuation, remove_messy,tokenize, remove_stop]\n",
    "\n",
    "\n",
    "def prepare(text, pipeline) : \n",
    "    tokens = str(text)\n",
    "    \n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)\n",
    "        \n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4c7c5a",
   "metadata": {},
   "source": [
    "### Feature extraction Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355a6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    feature_set = dict()\n",
    "    for word in text.split():\n",
    "        if word in fw:\n",
    "            feature_set[word] = True\n",
    "    return(feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe59220",
   "metadata": {},
   "source": [
    "### EDA functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb6edaf",
   "metadata": {},
   "source": [
    "* GET PATTERNS\n",
    "* WORD COUNTS\n",
    "* WORDCLOUD\n",
    "* TOPIC MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4409c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patterns(text_analyze, num_words, T):\n",
    "    if(len(text_analyze)==0):\n",
    "        raise ValueError(\"Can't work with empty text object\")\n",
    "    total_tokens = 1\n",
    "    unique_tokens = 0\n",
    "    avg_token_len = 0.0\n",
    "    lexical_diversityP = 0.0\n",
    "    top_words = []\n",
    "\n",
    "    # Only applying the token_normal, which takes only alphanumeric values\n",
    "    # to twitter data:\n",
    "    if T == 1:\n",
    "        text_analyze=token_normal(text_analyze)\n",
    "\n",
    "    total_tokens = len(text_analyze)\n",
    "    unique_tokens = len(set(text_analyze))\n",
    "    lexical_diversityP = unique_tokens/total_tokens\n",
    "    avg_token_len = np.mean([len(ta) for ta in text_analyze])\n",
    "\n",
    "    top_words_1 = collections.Counter(text_analyze)\n",
    "    top_words = top_words_1.most_common(num_words)\n",
    "\n",
    "    results={'tokens': total_tokens,\n",
    "             'unique_tokens': unique_tokens,\n",
    "             'avg_token_length': avg_token_len,\n",
    "             'lexical_diversity': lexical_diversityP,\n",
    "             'top_words': top_words}\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f16105",
   "metadata": {},
   "source": [
    "Word Cloud and Word Count Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035ee7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcloud(word_freq, title=None, max_words=200, stopwords=None):\n",
    "\n",
    "    wc = WordCloud(width=800, height=400, \n",
    "                   background_color= \"black\", colormap=\"Paired\", \n",
    "                   max_font_size=150, max_words=max_words)\n",
    "    \n",
    "    # convert data frame into dict\n",
    "    if type(word_freq) == pd.Series:\n",
    "        counter = Counter(word_freq.fillna(0).to_dict())\n",
    "    else:\n",
    "        counter = word_freq\n",
    "\n",
    "    # filter stop words in frequency counter\n",
    "    if stopwords is not None:\n",
    "        \n",
    "        counter = {token:freq for (token, freq) in counter.items() \n",
    "                              if token not in stopwords}\n",
    "    wc.generate_from_frequencies(counter)\n",
    " \n",
    "    plt.title(title) \n",
    "\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "# Here, we only apply splitting to the lyrics data due to the difference\n",
    "# in dataframe/data ingestion between twitter and lycis data:\n",
    "    \n",
    "#def count_words(df, column='tokens', preprocess=None, min_freq=2, split=0):\n",
    "def count_words(x, preprocess=None, min_freq=2, split=0):\n",
    "\n",
    "    # process tokens and update counter\n",
    "    def update(doc):\n",
    "        tokens = doc if preprocess is None else preprocess(doc)\n",
    "        counter.update(tokens)\n",
    "\n",
    "    # create counter and run through all data\n",
    "    #counter = collections.Counter()\n",
    "    #top_words_1 = collections.Counter(text_analyze)\n",
    "    #top_words = top_words_1.most_common(num_words)\n",
    "    if split == 0:\n",
    "        counter = collections.Counter(x)\n",
    "    else: \n",
    "        counter = collections.Counter(x.split())\n",
    "\n",
    "    #df[column].map(update)\n",
    "\n",
    "    # transform counter into data frame\n",
    "    freq_df = pd.DataFrame.from_dict(counter, orient='index', columns=['freq'])\n",
    "    freq_df = freq_df.query('freq >= @min_freq')\n",
    "    freq_df.index.name = 'token'\n",
    "    \n",
    "    return freq_df.sort_values('freq', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc2f478",
   "metadata": {},
   "source": [
    "Topic Modeling Display Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a04565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, features, no_top_words=5):\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1] # invert sort order\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\"  %s (%2.2f)\" % (features[largest[i]], \n",
    "                                    abs(words[largest[i]]*100.0/total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60293e77",
   "metadata": {},
   "source": [
    "Topical Word Clouds Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f315f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcloud_topics(model, features, no_top_words=40):\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        size = {}\n",
    "        largest = words.argsort()[::-1]\n",
    "        for i in range(0, no_top_words):\n",
    "            size[features[largest[i]]] = abs(words[largest[i]])\n",
    "        wc = WordCloud(background_color = 'white', max_words=100,\n",
    "                    width=960, height=540)\n",
    "        wc.generate_from_frequencies(size)\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.imshow(wc,interpolation='bilinear')\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8e9c33",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda7590",
   "metadata": {},
   "source": [
    "## Load Data from CSV's:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7d95a1",
   "metadata": {},
   "source": [
    "**Full Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9122a540",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_df = pd.read_csv('../data_large/data_preprocessed_wo_sw_2023-07-20_13-02-01408354.csv')\n",
    "news_data_w_sw_df = pd.read_csv('../data_large/data_preprocessed_w_sw_2023-07-20_13-02-01408354.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a11f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227809f8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4894e793",
   "metadata": {},
   "source": [
    "## EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ad92d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab0241c",
   "metadata": {},
   "source": [
    "### Format Publish Date for Time-Based EDA charts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f053ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df=news_data_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b32fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df['publish_date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040405a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#api_data_complete_df['publish_date_day']=api_data_complete_df['publish_date'].str[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df['publish_date'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c310a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#api_data_complete_df['publish_date_day']\n",
    "new_format = \"%Y-%m-%d\"\n",
    "for x in range(len(api_data_complete_df)):\n",
    "    api_data_complete_df.loc[x,'publish_date'] = \\\n",
    "    pd.to_datetime(api_data_complete_df.loc[x, 'publish_date'],\n",
    "                   format='%Y-%m-%dT%H:%M:%SZ').strftime(new_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c940c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df['publish_date'].head(6141)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c054bf8",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032108c",
   "metadata": {},
   "source": [
    "### Missing Values:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d77ed5",
   "metadata": {},
   "source": [
    "Only one missing value for training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222fbc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df = api_data_complete_df.dropna(axis=0,\n",
    "                                       subset=['processed_text']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae0b5e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac2ec7f",
   "metadata": {},
   "source": [
    "**Most missing data is from the author feature which is not relevant to our analysis. There are 3 records with missing processed_text which is used but insignificantly affects our final word count/topic modeling/sentiment analyses.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a602bfe7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc68af",
   "metadata": {},
   "source": [
    "### Descriptive Statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae3d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df['original_word_count'] = \\\n",
    "api_data_complete_df['article_text'].apply(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e870b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeb3d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df['num_tokens'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd2d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f754bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba320bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "# Plot the boxplot on the first subplot\n",
    "sns.boxplot(x=api_data_complete_df['num_tokens'], ax=axs[0])\n",
    "\n",
    "# Plot the histogram on the second subplot\n",
    "sns.histplot(x=api_data_complete_df['num_tokens'], ax=axs[1])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298d0469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot plus histogram of token distribution to see outliers\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "x = np.random.randn(100)\n",
    "\n",
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, \n",
    "                                    gridspec_kw={\"height_ratios\": (.25, .85)})\n",
    "sns.boxplot(x=api_data_complete_df['num_tokens'], ax=ax_box)\n",
    "sns.distplot(x=api_data_complete_df['num_tokens'], ax=ax_hist)\n",
    "ax_box.set(title='Number of Tokens per Article Distribution')\n",
    "ax_box.set_xlim([0, 4000])\n",
    "ax_hist.set_xlim([0, 4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b02fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df['num_tokens'].hist(bins=70)\n",
    "plt.title('Number of Tokens per Article Histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e1059",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df['num_tokens'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a9c537",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df.to_csv(\"../data_large/capstone_master_model_topic_input.csv\",\n",
    "                            sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296c169",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e446e33",
   "metadata": {},
   "source": [
    "Word counts had a right skew due to the very long length of 25% of articles. These articles were observed and deemed appropriate for inclusion in the dataset as they were not outliers, incorrect, or dirty data articles. The average, median, std deviation, 25th, 75th, minimum and maximum values are reported below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff697a",
   "metadata": {},
   "source": [
    "![Descriptive Statistics on Word Counts per Article](../data/desc_stats.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348cec0a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1daf4f",
   "metadata": {},
   "source": [
    "### Readability of articles:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4506610c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe2aff",
   "metadata": {},
   "source": [
    "Readability scores are calculated for all the articles, for EDA purposes. Interesting things to note were the journals that tended to have higher school grade level reading like the Washington Post, Reuters, and ABC News.\n",
    "\n",
    "The easiest reading level journals was BuzzFeed which had a 7th/8th grade reading level score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fef5f2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb50ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use data that includes stopwords for readability\n",
    "# and remove nulls from processed_text feature\n",
    "\n",
    "news_data_w_sw_df_2 = \\\n",
    "news_data_w_sw_df.dropna(axis=0, subset=['processed_text']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20345a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate readability using various metrics on the\n",
    "# processed text that includes stop words so it can\n",
    "# determine ease of reading/undersatnding by grade level\n",
    "# these scores are stored as features in the dataset\n",
    "\n",
    "readability = []\n",
    "dale_chall = []\n",
    "reading_time = []\n",
    "readability_overall = []\n",
    "for row in news_data_w_sw_df_2['processed_text']:\n",
    "    auto_readability_index_score = textstat.automated_readability_index(row)\n",
    "    dale_chall_readability_score = textstat.dale_chall_readability_score(row)\n",
    "    readingtime_score = textstat.reading_time(row, ms_per_char=14.69)\n",
    "    readability.append(auto_readability_index_score)\n",
    "    dale_chall.append(dale_chall_readability_score)\n",
    "    reading_time.append(readingtime_score)\n",
    "\n",
    "news_data_w_sw_df_2['auto_readability']=readability\n",
    "news_data_w_sw_df_2['dale_chall_readability']=dale_chall\n",
    "news_data_w_sw_df_2['reading_time']=reading_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea318810",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_w_sw_df_2['dale_chall_readability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f6327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_w_sw_df['auto_readability'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b173f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_w_sw_df_2\\\n",
    ".groupby(news_data_w_sw_df_2['source_name']==\"USA Today\")['reading_time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ee5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_w_sw_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b7fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_w_sw_df_3 = \\\n",
    "news_data_w_sw_df_2.dropna(axis=0, subset=['processed_text']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_w_sw_df_3['auto_readability'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960afe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_w_sw_df_3['dale_chall_readability'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_w_sw_df_3['reading_time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_plot_reading_time = news_data_w_sw_df_3[['source_name','reading_time']]\n",
    "news_data_plot_reading_time_avg = \\\n",
    "news_data_plot_reading_time\\\n",
    ".groupby(news_data_plot_reading_time['source_name'])['reading_time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_plot_autoread = news_data_w_sw_df_3[['source_name','auto_readability']]\n",
    "news_data_plot_autoread_avg = \\\n",
    "news_data_plot_autoread\\\n",
    ".groupby(news_data_plot_autoread['source_name'])['auto_readability'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038fdeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data_plot = news_data_w_sw_df_3[['source_name','dale_chall_readability']]\n",
    "news_data_plot_avg = news_data_plot\\\n",
    ".groupby(news_data_plot['source_name'])['dale_chall_readability'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcafbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dale_chall readability per news source:\n",
    "news_data_plot_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae9627",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_ar2 = news_data_plot_autoread_avg.plot(kind=\"line\",\n",
    "          x='source_name',\n",
    "          rot=0,\n",
    "          legend=True,\n",
    "          figsize=(8,4),\n",
    "          ylabel='School Grade Readabiity Score',\n",
    "          xlabel='News Source',\n",
    "          #='Political_Lean',\n",
    "          title='School grade Readability Score average across News Sources')\n",
    "#ax_ar2.bar_label(ax_ar2.containers[0])\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2544e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_ar = news_data_plot_autoread_avg.plot(kind=\"barh\",\n",
    "            y='source_name',\n",
    "            rot=0,\n",
    "            legend=True,\n",
    "            figsize=(8,12),\n",
    "            xlabel='School Grade Readabiity Score',\n",
    "            ylabel='News Source',\n",
    "            #='Political_Lean',\n",
    "            title='School grade Readability Score average across News Sources')\n",
    "ax_ar.bar_label(ax_ar.containers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a132f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_r = news_data_plot_reading_time_avg.plot(kind=\"barh\",\n",
    "                            y='source_name',\n",
    "                            rot=0,\n",
    "                            legend=True,\n",
    "                            figsize=(8,12),\n",
    "                            xlabel='Reading Time',\n",
    "                            ylabel='News Source',\n",
    "                            #='Political_Lean',\n",
    "                            title='Reading Time average across News Sources')\n",
    "ax_r.bar_label(ax_r.containers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3fa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#news_data_w_sw_df['auto_readability'].\n",
    "#ax1=news_data_w_sw_df_average\n",
    "#ax1=news_data_w_sw_df.groupby(news_data_w_sw_df['source_name'])['auto_readability']\n",
    "ax1 = news_data_plot_avg.plot(kind=\"barh\",\n",
    "            y='source_name',\n",
    "            rot=0,\n",
    "            legend=True,\n",
    "            figsize=(8,12),\n",
    "            xlabel='Dale Chall Score',\n",
    "            ylabel='News Source',\n",
    "            #='Political_Lean',\n",
    "            title='Dale Chall Readability Score average across News Sources')\n",
    "ax1.bar_label(ax1.containers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7419e46b",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c82e487",
   "metadata": {},
   "source": [
    "### A brief look into the long-length \"outlier-ISH\" articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da7ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#long_articles = api_data_complete_df.groupby(api_data_complete_df['num_tokens']>507)\n",
    "\n",
    "long_articles_idx = \\\n",
    "api_data_complete_df.groupby(api_data_complete_df['num_tokens'] > 507)[['url',\n",
    "                                                           'num_tokens',\n",
    "                                                           'processed_text']]\n",
    "long_articles_df = pd.DataFrame(long_articles_idx)\n",
    "long_articles_df.head()\n",
    "long_articles_df2 = pd.DataFrame(long_articles_df.iloc[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c6229",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_articles_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec945952",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_articles_df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRAlong_articles_idx = \\\n",
    "api_data_complete_df.groupby(api_data_complete_df['num_tokens'] >1000)[['url',\n",
    "                                                            'num_tokens',\n",
    "                                                            'processed_text']]\n",
    "XTRAlong_articles_df = pd.DataFrame(XTRAlong_articles_idx)\n",
    "XTRAlong_articles_df.head()\n",
    "XTRAlong_articles_df2 = pd.DataFrame(XTRAlong_articles_df.iloc[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9825d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRAlong_articles_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a957c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRAlong_articles_df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dc9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRAlong_articles_df2.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409ecf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRAlong_articles_df2.loc[2937,'url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dbe10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRAlong_articles_df2.loc[2937,'processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb63b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRAlong_articles_df2.loc[130,'url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRAlong_articles_df2.loc[130,'processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60243baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "XXTRAlong_articles_idx = \\\n",
    "api_data_complete_df.groupby(api_data_complete_df['num_tokens'] >3000)[['url',\n",
    "                                                            'num_tokens',\n",
    "                                                            'processed_text']]\n",
    "XXTRAlong_articles_df = pd.DataFrame(XXTRAlong_articles_idx)\n",
    "XXTRAlong_articles_df.head()\n",
    "XXTRAlong_articles_df2 = pd.DataFrame(XXTRAlong_articles_df.iloc[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "XXTRAlong_articles_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabef007",
   "metadata": {},
   "outputs": [],
   "source": [
    "XXTRAlong_articles_df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb75e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "XXTRAlong_articles_df2.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cf5496",
   "metadata": {},
   "outputs": [],
   "source": [
    "XXTRAlong_articles_df2.loc[789,'url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1789cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "XXTRAlong_articles_df2.loc[789,'processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f94910",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_articles_idx = \\\n",
    "XXTRAlong_articles_df2.groupby(XXTRAlong_articles_df2['processed_text']\\\n",
    "                                .str.contains('recommendation'))[['url',\n",
    "                                                              'num_tokens',\n",
    "                                                              'processed_text']]\n",
    "reviews_articles_df = pd.DataFrame(reviews_articles_idx)\n",
    "reviews_articles_df.head()\n",
    "reviews_articles_df2 = pd.DataFrame(reviews_articles_df.iloc[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa51e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NONreviews_articles_df2 = pd.DataFrame(reviews_articles_df.iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "NONreviews_articles_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e48c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NONreviews_articles_df2.loc[1335,'url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaad8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "NONreviews_articles_df2.loc[1335,'processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21019c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "XXTRAlong_articles_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f040125",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_articles_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba3807",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_articles_df2.tail(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa49e29",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edc3200",
   "metadata": {},
   "source": [
    "**Articles that had more than 1000 tokens tended to have a large number of reviews/recommendation of products or interviews. Above 3,000 tokens were almost entirely reviews. Therefore, the extra long articles in the corpus seem to be valid articles without the artifacts of ads or comments**\n",
    "\n",
    "**Of the articles with more than 3,000 words, which totalled 224, 178 were product recommendations, while others (from what can be gathered) appear to be stories or many mini parts of the same story with 'Click to Read More' links after each one.**\n",
    "\n",
    "**These longer articles are therefore not outliers of non-article content but a good amount of the super long articles are product recommendations, which may or may not be relevant in this study.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf3be69",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df['num_tokens'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0cc3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = api_data_complete_df['author'].value_counts()\n",
    "authors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be0e501",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab79f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df['author'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b685edae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4972140",
   "metadata": {},
   "source": [
    "**The number of total articles collected are *36,405* and since we found 3 records have missing processed text, we have a total number of records used for this analysis of *36,402*.** \n",
    "\n",
    "**Average Token count is *433.7793* words per article, with a median of *336* due to the extremely high counts in the data. The Histogram for the number of Tokens in each article is right skewed, as the difference between mean and medium indicates.**\n",
    "\n",
    "**The standard deviation (variability) is about as much *415.6439* given that there are a couple records with *0* words per article (were not parsed) and that there are some articles with significantly large token counts up to a maximum of *7240* words.**\n",
    "\n",
    "**The 75% percentile of 507 indicates most of the data lies in the lower range and just a few articles out of the 36,405 have word counts over 507.**\n",
    "\n",
    "**The total number of unique authors present in the data are *7,288*, with The Associated Press being the largest presence as 'author' with *1,847* articles attributed to them. This is without counting those with the authorship of \"Associated Press\" (absent \"The\"), which account for *504* articles attributed to that authorship.**\n",
    "\n",
    "**These results show we have gathered an adequate amount of data for our analysis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594351c4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09273258",
   "metadata": {},
   "source": [
    "### Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ebfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df['tokens'] = \\\n",
    "api_data_complete_df['processed_text'].apply(prepare,\n",
    "                                             pipeline=tokenize_sw_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5403fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_Words = [token for sublist in\n",
    "                api_data_complete_df['tokens'] \n",
    "                for token in sublist]\n",
    "Text_Words_counts = collections.Counter(Text_Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c906cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text_Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNews articles' top 20 words:\\n\")\n",
    "for HT, count in Text_Words_counts.most_common(20):\n",
    "    print(f\"{HT}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f369077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_Words_counts2 = count_words(Text_Words, split=0)\n",
    "#display(Text_Words_counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95448954",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud(Text_Words_counts2['freq'],\n",
    "          title=\"WordCloud of entire News Data Corpus\",\n",
    "          max_words=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f839968",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e94de",
   "metadata": {},
   "source": [
    "**With the preprocessing already done, the wordcloud doesn't tell us much. This is because it includes coverage of a variety of topics and news sources for the month of June. A deeper look into topics and sentiment might offer better opportunities to observe things like wordclouds and hence derive meaningful insights**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655ad220",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f722adab",
   "metadata": {},
   "source": [
    "### Topic Modeling Non-Negative Matrix (NMF):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb26b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_basic = [remove_punctuation,remove_messy]\n",
    "api_data_complete_df['clean_processed_text'] = \\\n",
    "api_data_complete_df['processed_text'].apply(prepare,\n",
    "                                             pipeline=pipeline_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_topic = TfidfVectorizer(stop_words=list(sw),\n",
    "                              min_df=5,\n",
    "                              max_df=0.7,\n",
    "                              ngram_range=(1,2))\n",
    "\n",
    "topic_modeling_input = \\\n",
    "tfidf_topic.fit_transform(api_data_complete_df['clean_processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_text_model_news = NMF(n_components=10, random_state=314)\n",
    "text_matrix = nmf_text_model_news.fit_transform(topic_modeling_input)\n",
    "H_text_matrix = nmf_text_model_news.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673745a8",
   "metadata": {},
   "source": [
    "Display Topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d84204",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(nmf_text_model_news, tfidf_topic.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef83464",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa050ed8",
   "metadata": {},
   "source": [
    "**Topic Modeling using NMF reveals that the top 10 topics present in news article data are:**\n",
    "\n",
    "* Sports/NBA\n",
    "* Sports/Baseball\n",
    "* Amazon/Review\n",
    "* Presidency/Government\n",
    "* Business/Work/Travel\n",
    "* Foreign Affairs/Ukraine/Russia\n",
    "* Technology/AI regulation\n",
    "* Titan Implosion\n",
    "* Economy/Inflation\n",
    "* Police/Court"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc41f64f",
   "metadata": {},
   "source": [
    "**Topics are well defined and clearly distinctive using NMF topic modeling.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7382f4c7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45093109",
   "metadata": {},
   "source": [
    "### Topic Modeling Latent Dirichlet Allocation (LDA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47df7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_text_vectorizer = CountVectorizer(stop_words=list(sw),\n",
    "                                        min_df=5,\n",
    "                                        max_df=0.7)\n",
    "\n",
    "count_text_vectors = count_text_vectorizer\\\n",
    ".fit_transform(api_data_complete_df['clean_processed_text'])\n",
    "count_text_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_para_model = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "W_lda_para_matrix = lda_para_model.fit_transform(count_text_vectors)\n",
    "H_lda_para_matrix = lda_para_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e8006",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(lda_para_model, count_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fec75eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_display = pyLDAvis.lda_model.prepare(lda_para_model,\n",
    "                                         count_text_vectors,\n",
    "                                         count_text_vectorizer,\n",
    "                                         sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ab3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(lda_display, 'lda_capstone1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b757ce6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eca10f",
   "metadata": {},
   "source": [
    "**Topic Modeling using LDA reveals that the top 10 topics present in news article data are:**\n",
    "\n",
    "* AI/business\n",
    "* Trump/Presidency\n",
    "* Rates/Market\n",
    "* One/People\n",
    "* Chine/School\n",
    "* Amazon/Review\n",
    "* Sports/Draft\n",
    "* Sports/Season\n",
    "* Police/Year\n",
    "* Million/Company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cff6847",
   "metadata": {},
   "source": [
    "**As we can see, the topics overlap and are not very clearly distinctive when using LDA topic modeling.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fbb535",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9efb0b",
   "metadata": {},
   "source": [
    "### Topic Coherence Score Adaptability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7e0c6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648dec64",
   "metadata": {},
   "source": [
    "An attempt is made here to modify the NMF topic model if we were to run this in real time with every new corpus of articles data. \n",
    "\n",
    "The approach is to modify the number of topics depending on Coherence scores that are calculated. In the end, this was not used in the current project, but is available for future work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e783a61a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbf7e7f",
   "metadata": {},
   "source": [
    "#### NMF Coherence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda92949",
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim = [[w for w in re.findall(r'\\b\\w\\w+\\b', text.lower()) if w not in sw] for text in api_data_complete_df['clean_processed_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9ca398",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_gensim = Dictionary(gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32bf237",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_gensim = [dict_gensim.doc2bow(word) for word in gensim]\n",
    "tfIdf_gensim = TfidfModel(bow_gensim)\n",
    "vectors_gensim = tfIdf_gensim[bow_gensim]\n",
    "#nmf_gensim=Nmf(topic_modeling_input, num_topics=10, id2word=dict_gensim, kappa=0.1, eval_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a0c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_gensim = Nmf(vectors_gensim,\n",
    "                 num_topics=10,\n",
    "                 id2word=dict_gensim,\n",
    "                 kappa=0.1,\n",
    "                 eval_every=5,\n",
    "                 random_state=314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_para_coherence = CoherenceModel(model=nmf_gensim,\n",
    "                                    texts=gensim,\n",
    "                                    dictionary=dict_gensim,\n",
    "                                    coherence='c_v')\n",
    "\n",
    "nmf_para_coherence_score = nmf_para_coherence.get_coherence()\n",
    "print(nmf_para_coherence_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5796303a",
   "metadata": {},
   "source": [
    "#### A function to quickly detect the ideal number of topics simply based on coherence scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4072129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ideal_topic_number(nmf_model, nmf_coherence, n_topics):\n",
    "    if (nmf_coherence < 0.69):\n",
    "        n_topics += n_topics+2\n",
    "        nmf_model = Nmf(vectors_gensim,\n",
    "                        num_topics=n_topics,\n",
    "                        id2word=dict_gensim,\n",
    "                        kappa=0.1,\n",
    "                        eval_every=5,\n",
    "                        random_state=314)\n",
    "        \n",
    "        nmf_coherence=nmf_para_coherence.get_coherence()\n",
    "        if nmf_coherence < 0.69:\n",
    "            n_topics += n_topics+2\n",
    "            nmf_model = Nmf(vectors_gensim,\n",
    "                            num_topics=n_topics,\n",
    "                            id2word=dict_gensim,\n",
    "                            kappa=0.1,\n",
    "                            eval_every=5,\n",
    "                            random_state=314)\n",
    "            \n",
    "            nmf_coherence=nmf_para_coherence.get_coherence()\n",
    "            if nmf_para_coherence_score < 0.69:\n",
    "                n_topics += n_topics+2\n",
    "                nmf_model = Nmf(vectors_gensim,\n",
    "                                num_topics=n_topics,\n",
    "                                id2word=dict_gensim,\n",
    "                                kappa=0.1,\n",
    "                                eval_every=5,\n",
    "                                random_state=314)\n",
    "                \n",
    "                nmf_coherence = nmf_para_coherence.get_coherence()\n",
    "            else:\n",
    "                return(nmf_model, nmf_coherence, n_topics)\n",
    "        else:\n",
    "            return(nmf_model, nmf_coherence, n_topics)\n",
    "    else:\n",
    "        return(nmf_model, nmf_coherence, n_topics)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a00c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_gensim, nmf_para_coherence_score, n_topics = \\\n",
    "find_ideal_topic_number(nmf_gensim,\n",
    "                        nmf_para_coherence_score,\n",
    "                        10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698c85a6",
   "metadata": {},
   "source": [
    "### Add NMF topics as features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15115c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the NMF for topic definitions with the current ideal\n",
    "# value for n_topics derived earlier:\n",
    "nmf_text_model_news = NMF(n_components=n_topics, random_state=314)\n",
    "text_matrix = nmf_text_model_news.fit_transform(topic_modeling_input)\n",
    "H_text_matrix = nmf_text_model_news.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d94302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = []\n",
    "voc = tfidf_topic.get_feature_names_out()\n",
    "for topic in nmf_text_model_news.components_:\n",
    "    important = topic.argsort()\n",
    "    top_word = voc[important[-1]] + \" \" + voc[important[-2]]\n",
    "    topic_names.append(top_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710de08f",
   "metadata": {},
   "source": [
    "Include other topics only if the weight is greater than 0.007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54805e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_ = defaultdict(list)\n",
    "for idx, row in enumerate(text_matrix) : \n",
    "    topic3 = np.where(row == np.amax(row))[0]\n",
    "    in_order = row.argsort()\n",
    "    #if (text_matrix[idx][in_order[9]]<0.006):\n",
    "    #    print(text_matrix[idx][in_order[9]])\n",
    "    if (text_matrix[idx][in_order[8]]>0.007):\n",
    "        topic2nd = in_order[8]\n",
    "    else:\n",
    "        topic2nd = \"\"\n",
    "    if (text_matrix[idx][in_order[7]]>0.007):\n",
    "        topic3rd =  in_order[7]\n",
    "    else:\n",
    "        topic3rd = \"\"\n",
    "    important_ = topic3.argsort()\n",
    "    #print(topic3, topic2nd, topic3rd)\n",
    "    api_data_complete_df.at[idx,\"topic\"]=topic3[0]\n",
    "    api_data_complete_df.at[idx,\"topic_name\"]=topic_names[topic3[0]]\n",
    "    if topic2nd != \"\":\n",
    "        api_data_complete_df.at[idx,\"topic_name_2nd\"] = topic_names[topic2nd]\n",
    "    else:\n",
    "        api_data_complete_df.at[idx,\"topic_name_2nd\"] = \"\"\n",
    "    if topic3rd != \"\":    \n",
    "        api_data_complete_df.at[idx,\"topic_name_3rd\"] = topic_names[topic3rd]\n",
    "    else:\n",
    "        api_data_complete_df.at[idx,\"topic_name_3rd\"] = \"\"\n",
    "    \n",
    "    #topic_[topic3[0]]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2cd8f1",
   "metadata": {},
   "source": [
    "Instead, it may be more effective to use proportions instead of weights to determine if we should include 2nd and 3rd topics of relevance. Use a threshold of 33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122acb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Obtain row-wise proportions for W matrix and convert top 3 topics over a\n",
    "threshold for each document to a (n, t) binary array, where n is the\n",
    "number of records and t is the number of topics citation:\n",
    "https://chat.openai.com/share/c8cbd38a-b024-4915-939d-cf5f9209926b\n",
    "'''\n",
    "np.set_printoptions(suppress=True,\n",
    "                    precision=4)\n",
    "\n",
    "# Calculate the row totals\n",
    "row_totals = np.sum(text_matrix, axis=1)\n",
    "\n",
    "# Divide each element in the array by its corresponding row total\n",
    "row_proportions = text_matrix / row_totals[:, np.newaxis]\n",
    "\n",
    "\n",
    "# Define the threshold for selection (0.33 in this case)\n",
    "threshold = 0.33\n",
    "n_top = 5\n",
    "\n",
    "# Create an empty array to store the results\n",
    "topic = np.zeros((len(row_proportions), 10), dtype=int)\n",
    "\n",
    "for idx, row in enumerate(row_proportions):\n",
    "    # Get indices of elements that satisfy the condition: above the threshold\n",
    "    above_threshold_indices = np.where(row > threshold)[0]\n",
    "    \n",
    "    # Sort the indices based on their corresponding values in descending order\n",
    "    sorted_indices = above_threshold_indices[np.argsort(row[above_threshold_indices])[::-1]]\n",
    "    \n",
    "    # Choose the top X indices if available, or fewer if there are fewer elements above the threshold\n",
    "    top_3_indices = sorted_indices[:min(n_top, len(sorted_indices))]\n",
    "    \n",
    "    # Set the corresponding elements in the 'topic' array to 1\n",
    "    topic[idx, top_3_indices] = 1\n",
    "\n",
    "\n",
    "api_data_complete_df['multilabel'] = topic.tolist()\n",
    "\n",
    "out_cols = ['text_id', 'source_name', 'processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predefined_topics = ['business',\n",
    "                     'politics/government',\n",
    "                     'sports',\n",
    "                     'shopping',\n",
    "                     'technology',\n",
    "                     'public_concerns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c9ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../capstone_master_customer_topics.npy\", list(predefined_topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddafe7f",
   "metadata": {},
   "source": [
    "### Topic Modeling Distribution Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094ef8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_overall = api_data_complete_df['topic_name'].value_counts(normalize=True)\n",
    "display(topics_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd1cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_overall_df = pd.DataFrame(topics_overall)\n",
    "topics_overall_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ffbcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_overall_df['proportion'] = round(topics_overall_df['proportion'],4)\n",
    "topics_overall_df = topics_overall_df.sort_values('proportion',\n",
    "                                                  ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc08120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topics_overall.\n",
    "ax4 = topics_overall_df['proportion'].plot(kind=\"barh\",\n",
    "                        x='topic_name',\n",
    "                        rot=0,\n",
    "                        legend=True,\n",
    "                        figsize=(8,12),\n",
    "                        xlabel='Topics',\n",
    "                        ylabel='Proportion',\n",
    "                        #='Political_Lean',\n",
    "                        title='Topics present in News Corpus by Proportions')\n",
    "ax4.bar_label(ax4.containers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f469702",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66295617",
   "metadata": {},
   "source": [
    "**The highest proportion of articles *27.24%* are about the topic \"Business Travel\" with \"Police Court\" following at *27.06%* and with the smallest proportion being \"Titanic Submersible\" at *1.91%***\n",
    "\n",
    "**Season/Draft (NBA sports) when added to Prop/Runs (Baseball sports), the Sports topic adds up to *20.57%***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ee6db",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78e389",
   "metadata": {},
   "source": [
    "### Map  Topics to generalized topics (for visualizations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfe5a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "predefined_topics = ['business',\n",
    "                     'politics/government',\n",
    "                     'sports',\n",
    "                     'shopping',\n",
    "                     'technology',\n",
    "                     'public_concerns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../capstone_master_customer_topics.npy\", list(predefined_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e27bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_topics(article_df):\n",
    "    customer_topics = []\n",
    "    mapped_topic = 'misc'\n",
    "    for items in article_df['topic_name']:\n",
    "        if (items == 'season draft') | (items == 'prop runs'):\n",
    "            mapped_topic = 'sports'\n",
    "        elif (items == 'trump president') | (items == 'russian prigozhin'):\n",
    "            mapped_topic = 'politics/government'\n",
    "        elif items == 'amazon review':\n",
    "            mapped_topic = 'shopping'\n",
    "        elif (items == 'inflation rates') | (items == 'business work'):\n",
    "            mapped_topic = 'business'\n",
    "        elif items == 'ai generative':\n",
    "            mapped_topic = 'technology'\n",
    "        elif (items == 'titanic submersible') | (items == 'police court'):\n",
    "            mapped_topic = 'public_concerns'\n",
    "        customer_topics.append(mapped_topic)\n",
    "    article_df['customer_topics'] = customer_topics\n",
    "    return article_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c1396",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_modeling_df = mapping_topics(api_data_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_modeling_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b03116",
   "metadata": {},
   "source": [
    "#### LDA coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a4e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_gensim = LdaModel(corpus=bow_gensim,\n",
    "                      id2word=dict_gensim,\n",
    "                      alpha='auto',\n",
    "                      eta='auto',\n",
    "                      num_topics=10,\n",
    "                      eval_every=None,\n",
    "                      random_state=315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe4802",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_coherence = CoherenceModel(model=lda_gensim,\n",
    "                               texts=gensim,\n",
    "                               dictionary=dict_gensim,\n",
    "                               coherence='c_v')\n",
    "\n",
    "lda_coherence_score = lda_coherence.get_coherence()\n",
    "print(lda_coherence_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d0307",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb9f209",
   "metadata": {},
   "source": [
    "**NMF topic modeling has a coherence score of *0.7506* while LDA topic modeling has a coherence score of *0.5274*.**\n",
    "\n",
    "**This is no surprised given the clarity of the topics found using NMF versus LDA where there were mixed topics overlapping one another as can be seen in the LDA charts. Since NMF has a much higher coherence score than LDA, we will use NMF topics for our future time-based charts for topic modeling.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bb8bd4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c04da8",
   "metadata": {},
   "source": [
    "#### LDA Coherence Plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4990558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_n=[]\n",
    "for n in tqdm(range(5,17)):\n",
    "    lda_model_test = LdaModel(corpus=bow_gensim,\n",
    "                              id2word=dict_gensim,\n",
    "                              alpha='auto',\n",
    "                              eta='auto',\n",
    "                              num_topics=n,\n",
    "                              eval_every=None,\n",
    "                              random_state=315)\n",
    "    \n",
    "    lda_coherence_test = CoherenceModel(model=lda_model_test,\n",
    "                                        texts=gensim,\n",
    "                                        dictionary=dict_gensim,\n",
    "                                        coherence='c_v')\n",
    "    lda_model_n.append((n, lda_model_test, lda_coherence_test.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e28019",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(lda_model_n, columns=['n','model','coherence'])\\\n",
    ".set_index('n')[['coherence']].plot(figsize=(16,9),\n",
    "                                    fontsize=16)\n",
    "plt.title('Coherence Scores based on Number of Topics using LDA topic modeling',\n",
    "          fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9434b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_gensim_test = Nmf(vectors_gensim,\n",
    "                      num_topics=11,\n",
    "                      id2word=dict_gensim,\n",
    "                      kappa=0.1,\n",
    "                      eval_every=5,\n",
    "                      random_state=314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42cabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_gensim_test.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88a9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_para_coherence_test = CoherenceModel(model=nmf_gensim_test,\n",
    "                                         texts=gensim,\n",
    "                                         dictionary=dict_gensim,\n",
    "                                         coherence='c_v')\n",
    "\n",
    "nmf_para_coherence_score_test = nmf_para_coherence_test.get_coherence()\n",
    "print(nmf_para_coherence_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096aa5b2",
   "metadata": {},
   "source": [
    "#### NMF Coherence plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e20c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model_n_plot=[]\n",
    "for n in tqdm(range(5,17)):\n",
    "    nmf_model_test_plot = Nmf(vectors_gensim,\n",
    "                              num_topics=n,\n",
    "                              id2word=dict_gensim,\n",
    "                              kappa=0.1,\n",
    "                              eval_every=5,\n",
    "                              random_state=314)\n",
    "    \n",
    "    nmf_coherence_test_plot = CoherenceModel(model=nmf_model_test_plot,\n",
    "                                             texts=gensim, \n",
    "                                             dictionary=dict_gensim,\n",
    "                                             coherence='c_v')\n",
    "    \n",
    "    nmf_model_n_plot.append((n,\n",
    "                             nmf_model_test_plot,\n",
    "                             nmf_coherence_test_plot.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9777a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(nmf_model_n_plot, columns=['n',\n",
    "                                        'model',\n",
    "                                        'coherence'])\\\n",
    ".set_index('n')[['coherence']].plot(figsize=(16,9),\n",
    "                                    fontsize=16)\n",
    "plt.title('Coherence Scores based on Number of Topics using NMF topic modeling',\n",
    "          fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db03c8a",
   "metadata": {},
   "source": [
    "Given that we should not opt for the highest coherence score, but rather, the more reasonable high score, ideal number of topics based on coherence score alone appear to be 11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f1c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_gensim_test = Nmf(vectors_gensim,\n",
    "                      num_topics=11,\n",
    "                      id2word=dict_gensim,\n",
    "                      kappa=0.1,\n",
    "                      eval_every=5,\n",
    "                      random_state=314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e3287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model_n_plot[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c993545",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_gensim_test.show_topics(num_words=5, formatted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e601cb",
   "metadata": {},
   "source": [
    "Topics are pretty well defined here and quite similar to the NMF model in scikit-learn - although at least 4 different topics are purely sports-related. These results are pretty similar to the results in our scikit-learn NMF model with 10 topics. Therefore, this confirms that the ideal number of topics lies in this region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3166c2c1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f980d132",
   "metadata": {},
   "source": [
    "**An important thing to note: The textbook Blueprints for Text Analytics Using Python by Jens Albrecht et al., warns against using the maximum value that gives the obvious highest coherence score because it is expected that coherence scores will increase as the number of topics increases. Therefore, a high coherence score alone this does not mean that with that number of topics, the topics will be better or more clearly defined.**\n",
    "\n",
    "**First, we apply coherence score analysis on LDA modeline, which has already been shown to have less well defined topics. Some models were done using LDA with the numbers considered ideal, but were found to have vague topics.**\n",
    "\n",
    "**Therefore, the same comparison is done for NMF topic modeling**\n",
    "\n",
    "**We should keep in mind we are using a different NMF algorithm for coherence score analysis. In this case, we are using gensim, while our final model is using scikit-learn. The reason for this is as follows:**\n",
    "\n",
    "**The coherence scores for gensim NMF topic modeling were calculated and then the ideal number is found. The one that gave the highest coherence score was 15 - with this, the topics were vague and not well defined. Therefore, the second highest score topic number was used: 11. The coherence score for this number of topics was *0.7415*. Here, we found similar topics to that of our scikit-learn NMF model. Yet, there is still some mixing of topics, so it was decided to move forward with the scikit-learn topic model that had better results that could be observed with the human eye.**\n",
    "\n",
    "**Given that the number of ideal topics for gensim was still 11, and with just slightly differently defined topics, it does appear the models are pretty similar in structure such that the ideal number of topics was between 10 and 11.**\n",
    "\n",
    "**This confirms in a mathematical manner the decision to move forward with NMF modeling, and with the number of topics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760596fb",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d3d0e8",
   "metadata": {},
   "source": [
    "### Topical Word Cloud Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b89a00",
   "metadata": {},
   "source": [
    "#### NMF Word Clouds for 10 topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4863b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_topics(nmf_text_model_news,\n",
    "                 tfidf_topic.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563aecc4",
   "metadata": {},
   "source": [
    "#### LDA Word Clouds for 10 topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eff19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_topics(lda_para_model,\n",
    "                 count_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19304481",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4841b2",
   "metadata": {},
   "source": [
    "### Generalized Topic Distribution Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b60726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall distribution of customer_topics across the data in proportions:\n",
    "\n",
    "api_data_complete_modeling_df['customer_topics']\\\n",
    ".value_counts(normalize=True).sort_values().plot(kind=\"barh\",\n",
    "                 legend=True,\n",
    "                 figsize=(5,6),\n",
    "                 title='Topic Distribution Proportions in Training/Test Data')\n",
    "plt.xticks(rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41434c44",
   "metadata": {},
   "source": [
    "### Topical Time-Based charts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day1 = api_data_complete_df[['publish_date', 'customer_topics']]\n",
    "topics_by_date = df_day1.groupby(df_day1['publish_date'])\\\n",
    ".value_counts(normalize=True)\n",
    "\n",
    "topics_by_date.head()\n",
    "\n",
    "\n",
    "df_day = pd.DataFrame(topics_by_date)#.set_index(0)\n",
    "df_day.head(20)\n",
    "dfg = df_day.groupby(['publish_date',\n",
    "                      'customer_topics']).agg({'proportion': sum}).reset_index()\n",
    "dfg.head()\n",
    "df = dfg.set_index(['publish_date', 'customer_topics']).unstack()\n",
    "df.plot()\n",
    "plt.title('Daily Topic Focus by Proportion')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.figure(figsize=(25, 7))\n",
    "\n",
    "\n",
    "df.plot.area(colormap=\"Pastel2\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Daily Topical Proportions')\n",
    "plt.figure(figsize=(25, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb90658",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462f4bc6",
   "metadata": {},
   "source": [
    "**The topic modeling charts above are generated using Non-Negative Matrix Topic modeling (since this model had more well-defined topics than Latent Dirichlet Allocation modeling) and reveal the most relevant topic in the beginning of June was \"Business and Travel,\" to then taper off to similar levels as that of \"Police and Court.\"**\n",
    "\n",
    "**Although TV media coverage was overwhelmingly about the titan submersible for that month, the online media does not exhibit this same behavior as it is covered, but not in a larger proportion as other topics.**\n",
    "\n",
    "**Sports coverage appears to be high in proportion as a topic for the month since the topics \"Season and Draft,\" which is likely about the NBA (after looking at the relevant wordcloud for this topic), and \"Prop and Runs,\" which is likely refering to Baseball both add up to be significant topics in proportion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5566c7f3",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d1d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_overall = api_data_complete_df['topic_name'].value_counts(normalize=True)\n",
    "display(topics_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e7f35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_overall_df = pd.DataFrame(topics_overall)\n",
    "topics_overall_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a85009",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_overall_df['proportion'] = round(topics_overall_df['proportion'],4)\n",
    "topics_overall_df = topics_overall_df.sort_values('proportion', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2717cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topics_overall.\n",
    "ax4 = topics_overall_df['proportion'].plot(kind=\"barh\",\n",
    "                        x='topic_name',\n",
    "                        rot=0,\n",
    "                        legend=True,\n",
    "                        figsize=(8,12),\n",
    "                        xlabel='Topics',\n",
    "                        ylabel='Proportion',\n",
    "                        #='Political_Lean',\n",
    "                        title='Topics present in News Corpus by Proportions')\n",
    "ax4.bar_label(ax4.containers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf54b9e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab774a",
   "metadata": {},
   "source": [
    "**The highest proportion of articles *27.24%* are about the topic \"Business Travel\" with \"Police Court\" following at *27.06%* and with the smallest proportion being \"Titanic Submersible\" at *1.91%***\n",
    "\n",
    "**Season/Draft (NBA sports) when added to Prop/Runs (Baseball sports), the Sports topic adds up to *20.57%***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbcfa6f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be21f8b",
   "metadata": {},
   "source": [
    "### Analysis of \"Amazon review\" Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d544f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df = \\\n",
    "pd.read_csv('../data/capstone_master_3topic_assignment_0725.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05af8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe35af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Amazon_articles_idx = \\\n",
    "api_data_complete_df\\\n",
    ".groupby(api_data_complete_df['topic_name'] == 'amazon review')['url']\n",
    "Amazon_articles_df = pd.DataFrame(Amazon_articles_idx)\n",
    "Amazon_articles_df.head()\n",
    "Amazon_articles_df2 = pd.DataFrame(Amazon_articles_df.iloc[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9a0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Amazon_articles_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Amazon_articles_df2.loc[16,'url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b722b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "Amazon_articles_df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4a8f2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eed668",
   "metadata": {},
   "source": [
    "**Upon deeper analysis of the topic_name \"amazon review,\" we find that the total number of articles categorized as this topic are *1,369*. Most of these articles are Review-based on items purchased on Amazon. But some are ads or others are actual stories. Given the small number overall and the difficulty in parsing out the articles that are related to ads or reviews without removing the valid stories, we will keep these articles for now and analyze positive sentiment articles to see if these show up to then filter accordingly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e558c30b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aad59c",
   "metadata": {},
   "source": [
    "### Save data for UI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb774d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_complete_df.to_csv(\"capstone_master_topic_assignment_0728.csv\",\n",
    "                            sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5f257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_back = pd.read_csv(\"capstone_master_topic_assignment_0728.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc2c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data_customer_topic=read_back.drop(['Unnamed: 0',\n",
    "                                            'index',\n",
    "                                            'author',\n",
    "                                            'article_text',\n",
    "                                            'processed_text',\n",
    "                                            'clean_processed_text',\n",
    "                                            'processed_text_split',\n",
    "                                            'num_tokens',\n",
    "                                            'original_word_count',\n",
    "                                            'topic',\n",
    "                                            'topic_name',\n",
    "                                            'topic_name_2nd',\n",
    "                                            'topic_name_3rd'],\n",
    "                                           axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data_customer_topic.to_csv(\"capstone_master_topic_assignment_0729.csv\",\n",
    "                                   sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b526da",
   "metadata": {},
   "source": [
    "----------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
